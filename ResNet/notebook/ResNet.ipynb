{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyNCl_djmf5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import optim\n",
        "import torch.backends.cudnn as cudnn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reCNXHf4pTyo",
        "colab_type": "code",
        "outputId": "3ae9068a-b68e-4248-af1c-6ff16b8cc7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "cudnn.benchmark = True\n",
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "name, driver_version, memory.total [MiB]\n",
            "Tesla P100-PCIE-16GB, 418.67, 16280 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-BjMXEaoAik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class To3Channels(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        if sample.shape[0] < 3:\n",
        "            sample = torch.squeeze(sample)\n",
        "            sample = torch.stack([sample, sample,sample], 0)\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdEC46rvmrf2",
        "colab_type": "code",
        "outputId": "17a5d045-7f25-4b6e-e5c3-5c36b5b145b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "transformer_cifar_10 =  torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.Resize(224),\n",
        "     torchvision.transforms.ToTensor(),\n",
        "     To3Channels(),\n",
        "     #torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
        "     torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "transformer_cifar_100 = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.Resize(224),\n",
        "     torchvision.transforms.ToTensor(),\n",
        "     To3Channels(),\n",
        "     torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "     #torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "transformer_fashion = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.Resize(224),\n",
        "     torchvision.transforms.ToTensor(),\n",
        "     To3Channels(),\n",
        "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "CIFAR10_train = torchvision.datasets.CIFAR10(\"../datasets/CIFAR10/\", train=True, transform=transformer_cifar_10, target_transform=None, download=True)\n",
        "CIFAR100_train = torchvision.datasets.CIFAR100(\"../datasets/CIFAR100/\", train=True, transform=transformer_cifar_100, target_transform=None, download=True)\n",
        "FashionMNIST_train = torchvision.datasets.FashionMNIST(\"../datasets/FashionMNIST/\", train=True, transform=transformer_fashion, target_transform=None, download=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "CIFAR10_test = torchvision.datasets.CIFAR10(\"../datasets/CIFAR10/\", train=False, transform=transformer_cifar_10, target_transform=None, download=True)\n",
        "CIFAR100_test = torchvision.datasets.CIFAR100(\"../datasets/CIFAR100/\", train=False, transform=transformer_cifar_100, target_transform=None, download=True)\n",
        "FashionMNIST_test = torchvision.datasets.FashionMNIST(\"../datasets/FashionMNIST/\", train=False, transform=transformer_fashion, target_transform=None, download=True)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-qyN6vbn8dM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_loaders(dataset = \"CIFAR10\"):\n",
        "    train_loader = None\n",
        "    test_loader = None\n",
        "    labels_num = None\n",
        "\n",
        "    if dataset == \"CIFAR10\":\n",
        "        train_loader = torch.utils.data.DataLoader(CIFAR10_train, batch_size=64,\n",
        "                                          shuffle=True, num_workers=8)\n",
        "        test_loader = torch.utils.data.DataLoader(CIFAR10_test, batch_size=64,\n",
        "                                          shuffle=False, num_workers=8)\n",
        "        labels_num = 10#len(set(CIFAR10_train.train_labels))\n",
        "    elif dataset == \"CIFAR100\":\n",
        "        train_loader = torch.utils.data.DataLoader(CIFAR100_train, batch_size=32,\n",
        "                                                   shuffle=True, num_workers=8)\n",
        "        test_loader = torch.utils.data.DataLoader(CIFAR100_test, batch_size=32,\n",
        "                                                  shuffle=False, num_workers=8)\n",
        "        labels_num = 100\n",
        "\n",
        "    elif dataset == \"FASHION_MNIST\":\n",
        "        train_loader = torch.utils.data.DataLoader(FashionMNIST_train, batch_size=64,\n",
        "                                                   shuffle=True, num_workers=8)\n",
        "        test_loader = torch.utils.data.DataLoader(FashionMNIST_test, batch_size=64,\n",
        "                                                  shuffle=False, num_workers=8)\n",
        "        labels_num = len(set(FashionMNIST_train.train_labels))\n",
        "\n",
        "\n",
        "    return train_loader,test_loader,labels_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0qfwb7Un17p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ShortcutBlock(nn.Module): \n",
        "    expansion = 1\n",
        "    def __init__(self, in_channel, out_channel,downsample_layer = None,stride=1):\n",
        "      super(ShortcutBlock,self).__init__()\n",
        "      self.conv1 =  nn.Conv2d(in_channel, out_channel,3, stride = stride,padding=1)\n",
        "      self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "      self.conv2 =  nn.Conv2d(out_channel, out_channel, 3,padding=1)\n",
        "      self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "      self.downsample = downsample_layer\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "    def forward(self,x):\n",
        "      identity = x\n",
        "      if self.downsample is not None:\n",
        "        identity = self.downsample(x)\n",
        "\n",
        "      x = self.relu(self.bn1(self.conv1(x)))\n",
        "      x = self.bn2(self.conv2(x))\n",
        "\n",
        "      return self.relu(identity + x)\n",
        "\n",
        "class BottleneckBlock(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self,in_channel, out_channel,downsample_layer = None,stride=1):\n",
        "      super(BottleneckBlock,self).__init__()\n",
        "      features = int(out_channel * (64 / 64.)) * 1\n",
        "\n",
        "      self.conv1 =  nn.Conv2d(in_channel, features,1)\n",
        "      self.bn1 = nn.BatchNorm2d(features)\n",
        "      self.conv2 =  nn.Conv2d(features, features, 3, stride = stride,padding=1)\n",
        "      self.bn2 = nn.BatchNorm2d(features)\n",
        "      self.conv3 =  nn.Conv2d(features, out_channel * self.expansion, 1)\n",
        "      self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
        "      self.downsample = downsample_layer\n",
        "      self.relu = nn.ReLU(inplace=True)\n",
        "      self.downsample = downsample_layer\n",
        "\n",
        "    def forward(self,x):\n",
        "      identity = x\n",
        "      if self.downsample is not None:\n",
        "        identity = self.downsample(x)\n",
        "      x = self.relu(self.bn1(self.conv1(x)))\n",
        "      x = self.relu(self.bn2(self.conv2(x)))\n",
        "      x = self.bn3(self.conv3(x))\n",
        "      return self.relu(identity + x)\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self,num_classes,block,layers):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.current_number_of_features = 64\n",
        "        self.conv1 = nn.Conv2d(3,64,7,stride=2,padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(3,stride=2)\n",
        "        self.block1 = self._construct_layer(block,64,layers[0])\n",
        "        self.block2 = self._construct_layer(block,128,layers[1],stride=2)\n",
        "        self.block3 = self._construct_layer(block,256,layers[2],stride=2)\n",
        "        self.block4 = self._construct_layer(block,512,layers[3],stride=2)\n",
        "        self.pool2 = nn.AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "        self.fc8 = nn.Linear(512 * block.expansion,num_classes)\n",
        "        #self.actv8 = nn.Softmax(dim=1)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _construct_layer(self, block, output_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "\n",
        "        # If the input is going to be downsampled (stride = 2) or the number of\n",
        "        #    channels is different from the expected expansion\n",
        "        if stride != 1 or self.current_number_of_features != output_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.current_number_of_features, output_channels * block.expansion, 1 , stride),\n",
        "                nn.BatchNorm2d(output_channels * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.current_number_of_features, output_channels, downsample, stride))\n",
        "        self.current_number_of_features = output_channels * block.expansion\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.current_number_of_features, output_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    def _forward_impl(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc8(x)\n",
        "        return x\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv_esqtZv52t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _resnet(block, layers,num_classes):\n",
        "    return ResNet(num_classes,block,layers)\n",
        "\n",
        "def ResNet18(num_classes):\n",
        "    return _resnet(ShortcutBlock,[2,2,2,2],num_classes)\n",
        "\n",
        "def ResNet34(num_classes):\n",
        "    return _resnet(ShortcutBlock,[3,4,6,3],num_classes)\n",
        "\n",
        "def ResNet50(num_classes):\n",
        "    \n",
        "    return _resnet(BottleneckBlock, [3, 4, 6, 3], num_classes)\n",
        "\n",
        "\n",
        "def ResNet101(num_classes):\n",
        "    \n",
        "    return _resnet(BottleneckBlock, [3, 4, 23, 3], num_classes)\n",
        "\n",
        "\n",
        "def ResNet152(num_classes):\n",
        "    return _resnet(BottleneckBlock, [3, 8, 36, 3], num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tqNq2UfoW_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(net, testloader):\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLUFPVaSoZ7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net,trainloader,testloader,optim_name = \"adam\",epochs = 30):\n",
        "    optimizer = optim.Adam(net.parameters(),lr= 0.001,weight_decay=0.0005)\n",
        "    if optim_name == \"sgd\":\n",
        "        optimizer = optim.SGD(net.parameters(),0.05,0.9,weight_decay=0.0005)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    for epoch in range(epochs):\n",
        "        #if epoch == 150: \n",
        "          #if optim_name == \"sgd\":\n",
        "        #    optimizer = optim.SGD(net.parameters(),0.01,0.9)\n",
        "        #if epoch == 250: \n",
        "        #  if optim_name == \"sgd\":\n",
        "        #    optimizer = optim.SGD(net.parameters(),0.001,0.9)\n",
        "        running_loss = 0.0\n",
        "        for i,data in enumerate(trainloader,0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if i % 300 == 299:  # print every 100 mini-batches\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 300))\n",
        "                losses.append(running_loss/300)\n",
        "                running_loss = 0.0\n",
        "\n",
        "        accuracy = compute_accuracy(net,testloader)\n",
        "        accuracies.append(accuracy)\n",
        "        print('Accuracy of the network on the test images: %.3f' % accuracy)\n",
        "\n",
        "    return accuracies,losses\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjho-fQAod41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "def run(dataset = \"CIFAR10\",epochs = 30):\n",
        "    trainloader, testloader, num_classes = get_loaders(dataset)\n",
        "\n",
        "    net = ResNet50(num_classes)\n",
        "    net.to(device)\n",
        "\n",
        "    accuracies, losses = train(net, trainloader, testloader,epochs=epochs,optim_name=\"adam\")\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    f = plt.figure(1)\n",
        "    x = np.linspace(0, 1, len(losses))\n",
        "    plt.plot(x,losses)\n",
        "    f.show()\n",
        "\n",
        "    g = plt.figure(2)\n",
        "    x = np.linspace(0, 1, len(accuracies))\n",
        "    plt.plot(x, accuracies, figure = g)\n",
        "    g.show()\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    #files.download( dataset + \"_loss.png\") \n",
        "    \n",
        "    \n",
        "    plt.show()\n",
        "    #files.download( dataset + \"_accuracy.png\")\n",
        "    \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XdVy8ITonJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run(epochs=70)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy25VbrhonN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run(\"CIFAR100\",80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cU-2CjsonS4",
        "colab_type": "code",
        "outputId": "2e568920-caaa-4ce8-bba5-bf5356fd6246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "run(\"FASHION_MNIST\",40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   300] loss: 0.750\n",
            "[1,   600] loss: 0.453\n",
            "[1,   900] loss: 0.417\n",
            "Accuracy of the network on the test images: 0.787\n",
            "[2,   300] loss: 4.532\n",
            "[2,   600] loss: 1.054\n",
            "[2,   900] loss: 0.734\n",
            "Accuracy of the network on the test images: 0.766\n",
            "[3,   300] loss: 0.604\n",
            "[3,   600] loss: 0.550\n",
            "[3,   900] loss: 0.523\n",
            "Accuracy of the network on the test images: 0.800\n",
            "[4,   300] loss: 0.490\n",
            "[4,   600] loss: 0.471\n",
            "[4,   900] loss: 0.458\n",
            "Accuracy of the network on the test images: 0.807\n",
            "[5,   300] loss: 0.443\n",
            "[5,   600] loss: 0.433\n",
            "[5,   900] loss: 0.422\n",
            "Accuracy of the network on the test images: 0.818\n",
            "[6,   300] loss: 0.415\n",
            "[6,   600] loss: 0.399\n",
            "[6,   900] loss: 0.411\n",
            "Accuracy of the network on the test images: 0.828\n",
            "[7,   300] loss: 0.396\n",
            "[7,   600] loss: 0.395\n",
            "[7,   900] loss: 0.383\n",
            "Accuracy of the network on the test images: 0.853\n",
            "[8,   300] loss: 0.364\n",
            "[8,   600] loss: 0.381\n",
            "[8,   900] loss: 0.367\n",
            "Accuracy of the network on the test images: 0.861\n",
            "[9,   300] loss: 0.352\n",
            "[9,   600] loss: 0.359\n",
            "[9,   900] loss: 0.357\n",
            "Accuracy of the network on the test images: 0.874\n",
            "[10,   300] loss: 0.341\n",
            "[10,   600] loss: 0.341\n",
            "[10,   900] loss: 0.341\n",
            "Accuracy of the network on the test images: 0.866\n",
            "[11,   300] loss: 0.330\n",
            "[11,   600] loss: 0.319\n",
            "[11,   900] loss: 0.330\n",
            "Accuracy of the network on the test images: 0.875\n",
            "[12,   300] loss: 0.314\n",
            "[12,   600] loss: 0.324\n",
            "[12,   900] loss: 0.309\n",
            "Accuracy of the network on the test images: 0.884\n",
            "[13,   300] loss: 0.308\n",
            "[13,   600] loss: 0.313\n",
            "[13,   900] loss: 0.310\n",
            "Accuracy of the network on the test images: 0.883\n",
            "[14,   300] loss: 0.303\n",
            "[14,   600] loss: 0.305\n",
            "[14,   900] loss: 0.296\n",
            "Accuracy of the network on the test images: 0.874\n",
            "[15,   300] loss: 0.295\n",
            "[15,   600] loss: 0.293\n",
            "[15,   900] loss: 0.298\n",
            "Accuracy of the network on the test images: 0.879\n",
            "[16,   300] loss: 0.283\n",
            "[16,   600] loss: 0.293\n",
            "[16,   900] loss: 0.293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fcd5bb84dd8>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
            "    w.join()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 124, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 50, in wait\n",
            "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 28, in poll\n",
            "    pid, sts = os.waitpid(self.pid, flag)\n",
            "KeyboardInterrupt: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-02fa0e61e73e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FASHION_MNIST\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-66790fdd1fb5>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-718e41ab1866>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, testloader, optim_name, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m300\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# print every 100 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}